{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader\n",
    "\n",
    "> Class for loading datasets on the research platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glob import glob\n",
    "import os\n",
    "from typing import List, Union\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pheno_utils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Class to load multiple tables from a dataset and allows to easily access\n",
    "    their fields.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "        dataset (str): The name of the dataset to load.\n",
    "        cohort (str, optional): The name of the cohort within the dataset. Defaults to '10k'.\n",
    "        base_path (str, optional): The base path where the data is stored. Defaults to '/home/ec2-user/studies'.\n",
    "        age_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to 'Population_Characteristics'.\n",
    "        unique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\n",
    "        valid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\n",
    "        valid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\n",
    "        errors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "            Possible values are 'raise' and 'warn'. Defaults to 'raise'.\n",
    "\n",
    "    Attributes:\n",
    "    \n",
    "        dict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\n",
    "        dfs (dict): A dictionary of dataframes, one for each table in the dataset.\n",
    "        fields (list): A list of all fields in the dataset.\n",
    "        dataset (str): The name of the dataset being used.\n",
    "        cohort (str): The name of the cohort being used.\n",
    "        base_path (str): The base path where the data is stored.\n",
    "        age_sex_dataset (str): The name of the dataset being used to compute age and sex.\n",
    "        unique_index (bool): Whether to ensure the index of the data is unique.\n",
    "        valid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\n",
    "        valid_stage (bool): Whether to ensure that all research stages in the data are valid.\n",
    "        errors (str): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: str,\n",
    "        cohort: str = '10k',\n",
    "        base_path: str = DATASETS_PATH,\n",
    "        age_sex_dataset: str = POPULATION_DATASET,\n",
    "        unique_index: bool = False,\n",
    "        valid_dates: bool = False,\n",
    "        valid_stage: bool = False,\n",
    "        errors: str = 'raise'\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.cohort = cohort\n",
    "        self.base_path = base_path\n",
    "        self.age_sex_dataset = age_sex_dataset\n",
    "        self.unique_index = unique_index\n",
    "        self.valid_dates = valid_dates\n",
    "        self.valid_stage = valid_stage\n",
    "        self.errors = errors\n",
    "\n",
    "        self.__load_dictionary__()\n",
    "        self.__load_dataframes__()\n",
    "        if self.age_sex_dataset is not None:\n",
    "            self.__load_age_sex__()\n",
    "\n",
    "    def load_sample(\n",
    "        self,\n",
    "        field_name: str,\n",
    "        participant_id: Union[str, List[str]],\n",
    "        research_stage: Union[None, str, List[str]] = None,\n",
    "        array_index: Union[None, int, List[int]] = None,\n",
    "        load_func: callable = pd.read_parquet,\n",
    "        concat: bool = True\n",
    "    ) -> Union[pd.DataFrame, None]:\n",
    "        \"\"\"\n",
    "        Load time series or bulk data for sample(s).\n",
    "\n",
    "        Args:\n",
    "            field_name (str): The name of the field to load.\n",
    "            participant_id (str or list): The participant ID or IDs to load data for.\n",
    "            research_stage (str or list, optional): The research stage or stages to load data for.\n",
    "            array_index (int or list, optional): The array index or indices to load data for.\n",
    "            load_func (callable, optional): The function to use to load the data. Defaults to pd.read\n",
    "            concat (bool, optional): Whether to concatenate the data into a single DataFrame. Defaults to True.\n",
    "        \"\"\"\n",
    "        query_str = 'participant_id in @participant_id'\n",
    "        if not isinstance(participant_id, list):\n",
    "            participant_id = [participant_id]\n",
    "        if research_stage is not None:\n",
    "            if not isinstance(research_stage, list):\n",
    "                research_stage = [research_stage]\n",
    "            query_str += ' and research_stage in @research_stage'\n",
    "        if array_index is not None:\n",
    "            if not isinstance(array_index, list):\n",
    "                array_index = [array_index]\n",
    "            query_str += ' and array_index in @array_index'\n",
    "\n",
    "        sample = self[[field_name] + ['participant_id']].query(query_str)\n",
    "        missing_participants = np.setdiff1d(participant_id, sample['participant_id'].unique())\n",
    "        sample = os.path.join(\n",
    "            self.base_path,\n",
    "            self.dataset,\n",
    "            self.cohort) + '/' + sample.iloc[:, 0]\n",
    "\n",
    "        if len(missing_participants):\n",
    "            if self.errors == 'raise':\n",
    "                raise ValueError(f'Missing samples: {missing_participants}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Missing samples: {missing_participants}')\n",
    "            if len(sample) == 0:\n",
    "                return None\n",
    "\n",
    "        data = [load_func(p) for p in sample.unique()]\n",
    "        if concat:\n",
    "            data = pd.concat(data, axis=0)\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return f'DataLoader for {self.dataset} with' +\\\n",
    "            f'\\n{len(self.fields)} fields\\n{len(self.dfs)} tables: {list(self.dfs.keys())}'\n",
    "\n",
    "    def __getitem__(self, fields):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (Union[str, List[str]]): Fields to return\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        if isinstance(fields, str):\n",
    "            fields = [fields]\n",
    "        return self.__get_data__(fields)\n",
    "\n",
    "    def __get_data__(self, fields):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (List[str]): Fields to return\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for df in self.dfs.values():\n",
    "            data.append(df[df.columns.intersection(fields)])\n",
    "        data = pd.concat(data, axis=1)\n",
    "        data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "        fields_in_index = np.intersect1d(fields, data.index.names)\n",
    "        for field in fields_in_index:\n",
    "            data[field] = data.index.get_level_values(field)\n",
    "\n",
    "        not_found = np.setdiff1d(fields, data.columns)\n",
    "        if len(not_found):\n",
    "            if self.errors == 'raise':\n",
    "                raise KeyError(f'Fields not found: {not_found}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Fileds not found: {not_found}')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __load_age_sex__(self) -> None:\n",
    "        \"\"\"\n",
    "        Add sex and compute age from birth date.\n",
    "        \"\"\"\n",
    "        age_path = os.path.join(\n",
    "            self.base_path,\n",
    "            self.age_sex_dataset,\n",
    "            self.cohort,\n",
    "            'events.parquet')\n",
    "        age_df = pd.read_parquet(age_path)\n",
    "        align_df = self.dfs[list(self.dfs)[0]]\n",
    "\n",
    "        # TODO: check if research stage is \"continuous\"\n",
    "        if ('research_stage' in align_df.columns) or ('research_stage' in align_df.index.names):\n",
    "            self.dfs['age_sex'] = align_df.join(\n",
    "                age_df[['age_at_research_stage', 'sex']].droplevel('array_index'))\\\n",
    "                .rename(columns={'age_at_research_stage': 'age'})\n",
    "            self.fields += ['age', 'sex']\n",
    "            return\n",
    "\n",
    "        date_cols = np.array(['collection_timestamp', 'collection_date', 'sequencing_date'])\n",
    "        date = date_cols[np.isin(date_cols, align_df.columns)][0]  # prefer first match\n",
    "\n",
    "        age_df['birth_date'] = pd.to_datetime(\n",
    "            age_df['year_of_birth'].astype(str) + '-' + age_df['month_of_birth'].astype(str))\n",
    "\n",
    "        self.dfs['age_sex'] = align_df[[date]].join(age_df[['sex', 'birth_date']])\\\n",
    "            .assign(age=lambda x: ((x[date].dt.date - x['birth_date'].dt.date).dt.days / 365.25).round(1))\\\n",
    "            .drop(columns=['birth_date'])\n",
    "        self.fields += ['age', 'sex']\n",
    "\n",
    "    def __load_dataframes__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load all tables in the dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dfs = {}\n",
    "        self.fields = set()\n",
    "        for relative_location in self.dict['relative_location'].dropna().unique():\n",
    "            self.dfs[relative_location.split('.')[0]] = self.__load_one_dataframe__(relative_location)\n",
    "            self.fields |= set(self.dfs[relative_location.split('.')[0]].columns.tolist())\n",
    "        self.fields = list(self.fields)\n",
    "\n",
    "    def __load_one_dataframe__(self, relative_location: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load one dataframe.\n",
    "\n",
    "        Args:\n",
    "            relative_location (str): the location of the dataframe\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: the loaded dataframe\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(\n",
    "            self.base_path,\n",
    "            self.dataset,\n",
    "            self.cohort,\n",
    "            relative_location)\n",
    "        data =  pd.read_parquet(df_path)\n",
    "\n",
    "        before = len(data)\n",
    "        if self.unique_index:\n",
    "            data = data.loc[~data.index.duplicated()]\n",
    "        if self.valid_dates:\n",
    "            data = data.loc[data.select_dtypes(include=['datetime64[ns]']).notnull().any(axis=1)]\n",
    "        if self.valid_stage:\n",
    "            data = data.loc[data.index.get_level_values('research_stage').notnull()]\n",
    "        after = len(data)\n",
    "        if before > after:\n",
    "            print(f'Filtered {before - after} rows')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __load_dictionary__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dict = pd.read_csv(self.__get_file_path__(self.dataset, 'csv'))\\\n",
    "            .set_index('tabular_field_name')\n",
    "        self.fields = self.dict.index.tolist()\n",
    "\n",
    "    def __get_file_path__(self, dataset: str, extension: str) -> str:\n",
    "        \"\"\"\n",
    "        Get the file path for a dataset and an extension.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): the name of the dataset\n",
    "            extension (str): the extension of the file\n",
    "\n",
    "        Returns:\n",
    "            str: the path to the file\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.base_path, dataset, self.cohort, '*.' + extension)\n",
    "        if path.startswith('s3://'):\n",
    "           return path\n",
    "        return glob(path)[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader for fundus with\n",
       "78 fields\n",
       "2 tables: ['fundus', 'age_sex']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader('Fundus')\n",
    "dl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary of the dataset displays the description of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_string</th>\n",
       "      <th>description_string</th>\n",
       "      <th>parent_dataframe</th>\n",
       "      <th>relative_location</th>\n",
       "      <th>value_type</th>\n",
       "      <th>units</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>item_type</th>\n",
       "      <th>array</th>\n",
       "      <th>cohorts</th>\n",
       "      <th>data_type</th>\n",
       "      <th>debut</th>\n",
       "      <th>pandas_dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabular_field_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fundus_image_left</th>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fundus_image_right</th>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_date</th>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Date</td>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>tabular</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timezone</th>\n",
       "      <td>Timezone</td>\n",
       "      <td>Timezone for timestamp columns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_timestamp</th>\n",
       "      <td>Collection timestamp</td>\n",
       "      <td>Collection timestamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>tabular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>datetime64[ns, Asia/Jerusalem]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      field_string  \\\n",
       "tabular_field_name                                   \n",
       "fundus_image_left              Fundus image (left)   \n",
       "fundus_image_right            Fundus image (right)   \n",
       "collection_date       Collection date (YYYY-MM-DD)   \n",
       "timezone                                  Timezone   \n",
       "collection_timestamp          Collection timestamp   \n",
       "\n",
       "                                  description_string  parent_dataframe  \\\n",
       "tabular_field_name                                                       \n",
       "fundus_image_left                Fundus image (left)               NaN   \n",
       "fundus_image_right              Fundus image (right)               NaN   \n",
       "collection_date         Collection date (YYYY-MM-DD)               NaN   \n",
       "timezone              Timezone for timestamp columns               NaN   \n",
       "collection_timestamp            Collection timestamp               NaN   \n",
       "\n",
       "                     relative_location value_type units  sampling_rate  \\\n",
       "tabular_field_name                                                       \n",
       "fundus_image_left       fundus.parquet      Text   None            NaN   \n",
       "fundus_image_right      fundus.parquet      Text   None            NaN   \n",
       "collection_date         fundus.parquet       Date  Time            NaN   \n",
       "timezone                fundus.parquet        NaN   NaN            NaN   \n",
       "collection_timestamp    fundus.parquet        NaN  Time            NaN   \n",
       "\n",
       "                     item_type   array cohorts data_type       debut  \\\n",
       "tabular_field_name                                                     \n",
       "fundus_image_left         Bulk  Single     10K     image  2021-02-17   \n",
       "fundus_image_right        Bulk  Single     10K     image  2021-02-17   \n",
       "collection_date           Data  Single     10K   tabular  2021-02-17   \n",
       "timezone                   NaN     NaN     NaN       NaN         NaN   \n",
       "collection_timestamp      Data  Single     10K   tabular         NaN   \n",
       "\n",
       "                                        pandas_dtype  \n",
       "tabular_field_name                                    \n",
       "fundus_image_left                             string  \n",
       "fundus_image_right                            string  \n",
       "collection_date                       datetime64[ns]  \n",
       "timezone                                      string  \n",
       "collection_timestamp  datetime64[ns, Asia/Jerusalem]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dict.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All availbale fields (columns) in all tables can be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distance_tortuosity_right',\n",
       " 'fundus_image_quality_good_score_right',\n",
       " 'average_width_left',\n",
       " 'artery_vessel_density_left',\n",
       " 'artery_distance_tortuosity_right']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.fields[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access any of the fields (e.g., `vein_average_width_right`, `age`) or indices (e.g., `research_stage`) from any of the tables via the data loader API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>vein_average_width_right</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>research_stage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10k</th>\n",
       "      <th>02_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>19196.368856</td>\n",
       "      <td>1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>02_00_visit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   vein_average_width_right  sex   age  \\\n",
       "cohort research_stage array_index                                        \n",
       "10k    02_00_visit    0                        19196.368856    1  56.8   \n",
       "\n",
       "                                  research_stage  \n",
       "cohort research_stage array_index                 \n",
       "10k    02_00_visit    0              02_00_visit  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl[['research_stage', 'vein_average_width_right', 'age', 'sex']].loc[5309837561]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample's bulk file from the main table (where it is stored in the field `fundus_image_left`), converts it to an absolute path, and loads the file. This is repeated for 3 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the `load_func` and the results are concatenated by deafult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=3494x3494>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=3500x3500>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=3458x3458>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_image(path):\n",
    "    return Image.open(open(path, 'rb'))\n",
    "\n",
    "dl.load_sample('fundus_image_left', [5950288169, 5948791269, 5580301087], load_func=load_image, concat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
