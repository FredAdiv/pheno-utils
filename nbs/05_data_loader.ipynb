{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class for loading datasets on the research platform\n",
    "output-file: data_loader.html\n",
    "title: Data loader\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glob import glob\n",
    "import os\n",
    "from typing import List, Union\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pheno_utils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Class to load multiple tables from a dataset and allows to easily access\n",
    "    their fields.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "        dataset (str): The name of the dataset to load.\n",
    "        cohort (str, optional): The name of the cohort within the dataset. Defaults to '10k'.\n",
    "        base_path (str, optional): The base path where the data is stored. Defaults to '/home/ec2-user/studies'.\n",
    "        age_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to 'Population_Characteristics'.\n",
    "        unique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\n",
    "        valid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\n",
    "        valid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\n",
    "        errors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "            Possible values are 'raise' and 'warn'. Defaults to 'raise'.\n",
    "\n",
    "    Attributes:\n",
    "    \n",
    "        dict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\n",
    "        dfs (dict): A dictionary of dataframes, one for each table in the dataset.\n",
    "        fields (list): A list of all fields in the dataset.\n",
    "        dataset (str): The name of the dataset being used.\n",
    "        cohort (str): The name of the cohort being used.\n",
    "        base_path (str): The base path where the data is stored.\n",
    "        age_sex_dataset (str): The name of the dataset being used to compute age and sex.\n",
    "        unique_index (bool): Whether to ensure the index of the data is unique.\n",
    "        valid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\n",
    "        valid_stage (bool): Whether to ensure that all research stages in the data are valid.\n",
    "        errors (str): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: str,\n",
    "        cohort: str = '10k',\n",
    "        base_path: str = DATASETS_PATH,\n",
    "        age_sex_dataset: str = POPULATION_DATASET,\n",
    "        skip_dfs: List[str] = [],\n",
    "        unique_index: bool = False,\n",
    "        valid_dates: bool = False,\n",
    "        valid_stage: bool = False,\n",
    "        errors: str = 'raise'\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.cohort = cohort\n",
    "        self.base_path = base_path\n",
    "        self.age_sex_dataset = age_sex_dataset\n",
    "        self.skip_dfs = skip_dfs\n",
    "        self.unique_index = unique_index\n",
    "        self.valid_dates = valid_dates\n",
    "        self.valid_stage = valid_stage\n",
    "        self.errors = errors\n",
    "\n",
    "        self.__load_dictionary__()\n",
    "        self.__load_dataframes__()\n",
    "        if self.age_sex_dataset is not None:\n",
    "            self.__load_age_sex__()\n",
    "\n",
    "    def load_sample_data(\n",
    "        self,\n",
    "        field_name: str,\n",
    "        participant_id: Union[str, List[str]],\n",
    "        research_stage: Union[None, str, List[str]] = None,\n",
    "        array_index: Union[None, int, List[int]] = None,\n",
    "        load_func: callable = pd.read_parquet,\n",
    "        concat: bool = True\n",
    "    ) -> Union[pd.DataFrame, None]:\n",
    "        \"\"\"\n",
    "        Load time series or bulk data for sample(s).\n",
    "\n",
    "        Args:\n",
    "            field_name (str): The name of the field to load.\n",
    "            participant_id (str or list): The participant ID or IDs to load data for.\n",
    "            research_stage (str or list, optional): The research stage or stages to load data for.\n",
    "            array_index (int or list, optional): The array index or indices to load data for.\n",
    "            load_func (callable, optional): The function to use to load the data. Defaults to pd.read\n",
    "            concat (bool, optional): Whether to concatenate the data into a single DataFrame. Defaults to True.\n",
    "        \"\"\"\n",
    "        query_str = 'participant_id in @participant_id'\n",
    "        if not isinstance(participant_id, list):\n",
    "            participant_id = [participant_id]\n",
    "        if research_stage is not None:\n",
    "            if not isinstance(research_stage, list):\n",
    "                research_stage = [research_stage]\n",
    "            query_str += ' and research_stage in @research_stage'\n",
    "        if array_index is not None:\n",
    "            if not isinstance(array_index, list):\n",
    "                array_index = [array_index]\n",
    "            query_str += ' and array_index in @array_index'\n",
    "\n",
    "        sample = self[[field_name] + ['participant_id']].query(query_str)\n",
    "        missing_participants = np.setdiff1d(participant_id, sample['participant_id'].unique())\n",
    "        sample = os.path.join(\n",
    "            self.base_path,\n",
    "            self.dataset,\n",
    "            self.cohort) + '/' + sample.iloc[:, 0]\n",
    "\n",
    "        if len(missing_participants):\n",
    "            if self.errors == 'raise':\n",
    "                raise ValueError(f'Missing samples: {missing_participants}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Missing samples: {missing_participants}')\n",
    "            if len(sample) == 0:\n",
    "                return None\n",
    "\n",
    "        data = []\n",
    "        for p in sample.unique():\n",
    "            try:\n",
    "                data.append(load_func(p))\n",
    "            except Exception as e:\n",
    "                if self.errors == 'raise':\n",
    "                    raise e\n",
    "                elif self.errors == 'warn':\n",
    "                    warnings.warn(f'Error loading {p}: {e}')\n",
    "        if concat:\n",
    "            data = pd.concat(data, axis=0)\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return f'DataLoader for {self.dataset} with' +\\\n",
    "            f'\\n{len(self.fields)} fields\\n{len(self.dfs)} tables: {list(self.dfs.keys())}'\n",
    "\n",
    "    def __getitem__(self, fields):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (Union[str, List[str]]): Fields to return\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        if isinstance(fields, str):\n",
    "            fields = [fields]\n",
    "        return self.__get_data__(fields)\n",
    "\n",
    "    def __get_data__(self, fields):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (List[str]): Fields to return\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for df in self.dfs.values():\n",
    "            data.append(df[df.columns.intersection(fields)])\n",
    "        data = pd.concat(data, axis=1)\n",
    "        data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "        fields_in_index = np.intersect1d(fields, data.index.names)\n",
    "        for field in fields_in_index:\n",
    "            data[field] = data.index.get_level_values(field)\n",
    "\n",
    "        not_found = np.setdiff1d(fields, data.columns)\n",
    "        if len(not_found):\n",
    "            if self.errors == 'raise':\n",
    "                raise KeyError(f'Fields not found: {not_found}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Fileds not found: {not_found}')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __load_age_sex__(self) -> None:\n",
    "        \"\"\"\n",
    "        Add sex and compute age from birth date.\n",
    "        \"\"\"\n",
    "        age_path = os.path.join(\n",
    "            self.base_path,\n",
    "            self.age_sex_dataset,\n",
    "            self.cohort,\n",
    "            'events.parquet')\n",
    "        age_df = pd.read_parquet(age_path)\n",
    "        align_df = self.dfs[list(self.dfs)[0]]\n",
    "\n",
    "        # TODO: check if research stage is \"continuous\"\n",
    "        if ('research_stage' in align_df.columns) or ('research_stage' in align_df.index.names):\n",
    "            self.dfs['age_sex'] = align_df.join(\n",
    "                age_df[['age_at_research_stage', 'sex']].droplevel('array_index'))\\\n",
    "                .rename(columns={'age_at_research_stage': 'age'})\n",
    "            self.fields += ['age', 'sex']\n",
    "            return\n",
    "\n",
    "        date_cols = np.array(['collection_timestamp', 'collection_date', 'sequencing_date'])\n",
    "        date = date_cols[np.isin(date_cols, align_df.columns)][0]  # prefer first match\n",
    "\n",
    "        age_df['birth_date'] = pd.to_datetime(\n",
    "            age_df['year_of_birth'].astype(str) + '-' + age_df['month_of_birth'].astype(str))\n",
    "\n",
    "        self.dfs['age_sex'] = align_df[[date]].join(age_df[['sex', 'birth_date']])\\\n",
    "            .assign(age=lambda x: ((x[date].dt.date - x['birth_date'].dt.date).dt.days / 365.25).round(1))\\\n",
    "            .drop(columns=['birth_date'])\n",
    "        self.fields += ['age', 'sex']\n",
    "\n",
    "    def __load_dataframes__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load all tables in the dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dfs = {}\n",
    "        self.fields = set()\n",
    "        for relative_location in self.dict['relative_location'].dropna().unique():\n",
    "            if any([pattern in relative_location for pattern in self.skip_dfs]):\n",
    "                print(f'Skipping {relative_location}')\n",
    "                continue\n",
    "            self.dfs[relative_location.split('.')[0]] = self.__load_one_dataframe__(relative_location)\n",
    "            self.fields |= set(self.dfs[relative_location.split('.')[0]].columns.tolist())\n",
    "        self.fields = list(self.fields)\n",
    "\n",
    "    def __load_one_dataframe__(self, relative_location: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load one dataframe.\n",
    "\n",
    "        Args:\n",
    "            relative_location (str): the location of the dataframe\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: the loaded dataframe\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(\n",
    "            self.base_path,\n",
    "            self.dataset,\n",
    "            self.cohort,\n",
    "            relative_location)\n",
    "        try:\n",
    "            data =  pd.read_parquet(df_path)\n",
    "        except Exception as err:\n",
    "            if self.errors == 'raise':\n",
    "                raise err\n",
    "            if self.errors == 'warn':\n",
    "                warnings.warn(f'Error loading {df_path}:\\n{err}')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # set the order of columns according to the dictionary\n",
    "        dict_columns = self.dict.index.intersection(data.columns)\n",
    "        other_columns = data.columns.difference(self.dict.index)\n",
    "        assert (len(dict_columns) + len(other_columns)) == len(data.columns), \"something isn't right\"\n",
    "        data = data[dict_columns.tolist() + other_columns.tolist()]\n",
    "\n",
    "        before = len(data)\n",
    "        if self.unique_index:\n",
    "            data = data.loc[~data.index.duplicated()]\n",
    "        if self.valid_dates:\n",
    "            data = data.loc[data.select_dtypes(include=['datetime64[ns]']).notnull().any(axis=1)]\n",
    "        if self.valid_stage:\n",
    "            data = data.loc[data.index.get_level_values('research_stage').notnull()]\n",
    "        after = len(data)\n",
    "        if before > after:\n",
    "            print(f'Filtered {before - after} rows')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __load_dictionary__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dict = pd.read_csv(self.__get_file_path__(self.dataset, 'csv'))\\\n",
    "            .set_index('tabular_field_name')\n",
    "        self.fields = self.dict.index.tolist()\n",
    "\n",
    "    def __get_file_path__(self, dataset: str, extension: str) -> str:\n",
    "        \"\"\"\n",
    "        Get the file path for a dataset and an extension.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): the name of the dataset\n",
    "            extension (str): the extension of the file\n",
    "\n",
    "        Returns:\n",
    "            str: the path to the file\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.base_path, dataset, self.cohort, '*.' + extension)\n",
    "        if path.startswith('s3://'):\n",
    "           return path\n",
    "        return glob(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping relatives/plink_ibs.parquet\n",
      "Skipping relatives/king_kinship.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73434/2248394877.py:250: UserWarning: Error loading s3://phenodatasets/human_genetics/10k/pca/eigenvec.var:\n",
      "Could not open Parquet input source 'phenodatasets/human_genetics/10k/pca/eigenvec.var': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "  warnings.warn(f'Error loading {df_path}:\\n{err}')\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader('human_genetics', base_path='s3://phenodatasets', age_sex_dataset='population',\n",
    "                errors='warn', skip_dfs=['relatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>collection_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>array_index</th>\n",
       "      <th>research_stage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1000942861</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>1</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_00_call</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>1</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1001201093</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_00_call</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002033709</th>\n",
       "      <th>10k</th>\n",
       "      <th>0</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9999226141</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">10k</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_00_call</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_00_call</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9999409119</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>54.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_00_call</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>54.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19706 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 collection_date  sex   age\n",
       "participant_id cohort array_index research_stage                           \n",
       "1000942861     10k    0           00_00_visit         2022-05-16    1  54.8\n",
       "                                  01_00_call          2022-05-16    1  54.8\n",
       "1001201093     10k    0           00_00_visit         2021-11-24    0  42.3\n",
       "                                  01_00_call          2021-11-24    0  42.3\n",
       "1002033709     10k    0           00_00_visit         2022-11-30    0  43.2\n",
       "...                                                          ...  ...   ...\n",
       "9999226141     10k    0           00_00_visit         2021-07-27    1  43.1\n",
       "                                  03_00_call          2021-07-27    1  43.1\n",
       "                                  01_00_call          2021-07-27    1  43.1\n",
       "9999409119     10k    0           00_00_visit         2020-09-23    0  54.1\n",
       "                                  01_00_call          2020-09-23    0  54.1\n",
       "\n",
       "[19706 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dfs['age_sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>collection_date</th>\n",
       "      <th>version</th>\n",
       "      <th>genecov_qc_bases</th>\n",
       "      <th>genecov_qc_bases_dedup</th>\n",
       "      <th>gencove_qc_bases_dedup_mapped</th>\n",
       "      <th>genecov_qc_effective_coverage</th>\n",
       "      <th>genecov_qc_fraction_contamination</th>\n",
       "      <th>genecov_qc_snps</th>\n",
       "      <th>genecov_qc_format_passed</th>\n",
       "      <th>genecov_qc_r1_eq_r2_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>postqc_bim_chr_19</th>\n",
       "      <th>postqc_bed_chr_20</th>\n",
       "      <th>postqc_fam_chr_20</th>\n",
       "      <th>postqc_bim_chr_20</th>\n",
       "      <th>postqc_bed_chr_21</th>\n",
       "      <th>postqc_fam_chr_21</th>\n",
       "      <th>postqc_bim_chr_21</th>\n",
       "      <th>postqc_bed_chr_22</th>\n",
       "      <th>postqc_fam_chr_22</th>\n",
       "      <th>postqc_bim_chr_22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10k</th>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>v02</td>\n",
       "      <td>2.048679e+09</td>\n",
       "      <td>1.806727e+09</td>\n",
       "      <td>1.691509e+09</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>0.005</td>\n",
       "      <td>27119329.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>variants_postqc/chr_19.bim</td>\n",
       "      <td>variants_postqc/chr_20.bed</td>\n",
       "      <td>variants_postqc/chr_20.fam</td>\n",
       "      <td>variants_postqc/chr_20.bim</td>\n",
       "      <td>variants_postqc/chr_21.bed</td>\n",
       "      <td>variants_postqc/chr_21.fam</td>\n",
       "      <td>variants_postqc/chr_21.bim</td>\n",
       "      <td>variants_postqc/chr_22.bed</td>\n",
       "      <td>variants_postqc/chr_22.fam</td>\n",
       "      <td>variants_postqc/chr_22.bim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   collection_date version  genecov_qc_bases  \\\n",
       "cohort array_index                                             \n",
       "10k    0                2022-05-16     v02      2.048679e+09   \n",
       "\n",
       "                    genecov_qc_bases_dedup  gencove_qc_bases_dedup_mapped  \\\n",
       "cohort array_index                                                          \n",
       "10k    0                      1.806727e+09                   1.691509e+09   \n",
       "\n",
       "                    genecov_qc_effective_coverage  \\\n",
       "cohort array_index                                  \n",
       "10k    0                                 0.385886   \n",
       "\n",
       "                    genecov_qc_fraction_contamination  genecov_qc_snps  \\\n",
       "cohort array_index                                                       \n",
       "10k    0                                        0.005       27119329.0   \n",
       "\n",
       "                   genecov_qc_format_passed genecov_qc_r1_eq_r2_passed  ...  \\\n",
       "cohort array_index                                                      ...   \n",
       "10k    0                               True                       True  ...   \n",
       "\n",
       "                             postqc_bim_chr_19           postqc_bed_chr_20  \\\n",
       "cohort array_index                                                           \n",
       "10k    0            variants_postqc/chr_19.bim  variants_postqc/chr_20.bed   \n",
       "\n",
       "                             postqc_fam_chr_20           postqc_bim_chr_20  \\\n",
       "cohort array_index                                                           \n",
       "10k    0            variants_postqc/chr_20.fam  variants_postqc/chr_20.bim   \n",
       "\n",
       "                             postqc_bed_chr_21           postqc_fam_chr_21  \\\n",
       "cohort array_index                                                           \n",
       "10k    0            variants_postqc/chr_21.bed  variants_postqc/chr_21.fam   \n",
       "\n",
       "                             postqc_bim_chr_21           postqc_bed_chr_22  \\\n",
       "cohort array_index                                                           \n",
       "10k    0            variants_postqc/chr_21.bim  variants_postqc/chr_22.bed   \n",
       "\n",
       "                             postqc_fam_chr_22           postqc_bim_chr_22  \n",
       "cohort array_index                                                          \n",
       "10k    0            variants_postqc/chr_22.fam  variants_postqc/chr_22.bim  \n",
       "\n",
       "[1 rows x 185 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dfs['main'].loc[1000942861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56849/469783573.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'postqc_fam_chr_22'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6104973108\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_56849/963001822.py\u001b[0m in \u001b[0;36mload_sample_data\u001b[0;34m(self, field_name, participant_id, research_stage, array_index, load_func, concat)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mquery_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' and array_index in @array_index'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mmissing_participants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         sample = os.path.join(\n",
      "\u001b[0;32m/tmp/ipykernel_56849/963001822.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, fields)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_data__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_data__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_56849/963001822.py\u001b[0m in \u001b[0;36m__get_data__\u001b[0;34m(self, fields)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;36m1\u001b[0m   \u001b[0;36m3\u001b[0m   \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concat_axis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         return [\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concat_axis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_comb_axis\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mdata_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         return get_objs_combined_axis(\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36mget_objs_combined_axis\u001b[0;34m(objs, intersect, axis, sort, copy)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m    104\u001b[0m     \u001b[0mobs_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_combined_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_idxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m_get_combined_index\u001b[0;34m(indexes, intersect, sort, copy)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munion_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36munion_indexes\u001b[0;34m(indexes, sort)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   3352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_reconciled_name_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3354\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_setop_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_union\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   3641\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_unique_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3643\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3645\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_comparable_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeObj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dl.load_sample_data('postqc_fam_chr_22', 6104973108)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default. The default `base_path` is set to work on the research platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader for Fundus with\n",
       "78 fields\n",
       "2 tables: ['fundus', 'age_sex']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader('Fundus', base_path='examples/', errors='warn')\n",
    "dl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary of the dataset displays the description of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_string</th>\n",
       "      <th>description_string</th>\n",
       "      <th>parent_dataframe</th>\n",
       "      <th>relative_location</th>\n",
       "      <th>value_type</th>\n",
       "      <th>units</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>item_type</th>\n",
       "      <th>array</th>\n",
       "      <th>cohorts</th>\n",
       "      <th>data_type</th>\n",
       "      <th>debut</th>\n",
       "      <th>pandas_dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabular_field_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fundus_image_left</th>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fundus_image_right</th>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_date</th>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundus.parquet</td>\n",
       "      <td>Date</td>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>tabular</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    field_string  \\\n",
       "tabular_field_name                                 \n",
       "fundus_image_left            Fundus image (left)   \n",
       "fundus_image_right          Fundus image (right)   \n",
       "collection_date     Collection date (YYYY-MM-DD)   \n",
       "\n",
       "                              description_string  parent_dataframe  \\\n",
       "tabular_field_name                                                   \n",
       "fundus_image_left            Fundus image (left)               NaN   \n",
       "fundus_image_right          Fundus image (right)               NaN   \n",
       "collection_date     Collection date (YYYY-MM-DD)               NaN   \n",
       "\n",
       "                   relative_location value_type units  sampling_rate  \\\n",
       "tabular_field_name                                                     \n",
       "fundus_image_left     fundus.parquet      Text   None            NaN   \n",
       "fundus_image_right    fundus.parquet      Text   None            NaN   \n",
       "collection_date       fundus.parquet       Date  Time            NaN   \n",
       "\n",
       "                   item_type   array cohorts data_type       debut  \\\n",
       "tabular_field_name                                                   \n",
       "fundus_image_left       Bulk  Single     10K     image  2021-02-17   \n",
       "fundus_image_right      Bulk  Single     10K     image  2021-02-17   \n",
       "collection_date         Data  Single     10K   tabular  2021-02-17   \n",
       "\n",
       "                      pandas_dtype  \n",
       "tabular_field_name                  \n",
       "fundus_image_left           string  \n",
       "fundus_image_right          string  \n",
       "collection_date     datetime64[ns]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dict.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fundus_image_left</th>\n",
       "      <th>fundus_image_right</th>\n",
       "      <th>collection_date</th>\n",
       "      <th>artery_average_width_left</th>\n",
       "      <th>artery_average_width_right</th>\n",
       "      <th>artery_distance_tortuosity_left</th>\n",
       "      <th>artery_distance_tortuosity_right</th>\n",
       "      <th>artery_fractal_dimension_left</th>\n",
       "      <th>artery_fractal_dimension_right</th>\n",
       "      <th>artery_squared_curvature_tortuosity_left</th>\n",
       "      <th>...</th>\n",
       "      <th>vein_fractal_dimension_left</th>\n",
       "      <th>vein_fractal_dimension_right</th>\n",
       "      <th>vein_squared_curvature_tortuosity_left</th>\n",
       "      <th>vein_squared_curvature_tortuosity_right</th>\n",
       "      <th>vein_tortuosity_density_left</th>\n",
       "      <th>vein_tortuosity_density_right</th>\n",
       "      <th>vein_vessel_density_left</th>\n",
       "      <th>vein_vessel_density_right</th>\n",
       "      <th>vessel_density_left</th>\n",
       "      <th>vessel_density_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>18430.284751</td>\n",
       "      <td>19038.547771</td>\n",
       "      <td>3.668175</td>\n",
       "      <td>3.271147</td>\n",
       "      <td>1.355673</td>\n",
       "      <td>1.343602</td>\n",
       "      <td>40.648267</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410553</td>\n",
       "      <td>1.403108</td>\n",
       "      <td>14.208195</td>\n",
       "      <td>6.098432</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.046645</td>\n",
       "      <td>0.045864</td>\n",
       "      <td>0.080377</td>\n",
       "      <td>0.078671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>17315.398780</td>\n",
       "      <td>19099.489575</td>\n",
       "      <td>2.095461</td>\n",
       "      <td>1.634782</td>\n",
       "      <td>1.368933</td>\n",
       "      <td>1.363413</td>\n",
       "      <td>24.253169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.387527</td>\n",
       "      <td>1.332864</td>\n",
       "      <td>8.999069</td>\n",
       "      <td>8.702682</td>\n",
       "      <td>0.740806</td>\n",
       "      <td>0.708911</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.074197</td>\n",
       "      <td>0.064578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>15375.866993</td>\n",
       "      <td>19855.576862</td>\n",
       "      <td>2.776472</td>\n",
       "      <td>2.747015</td>\n",
       "      <td>1.360404</td>\n",
       "      <td>1.362699</td>\n",
       "      <td>9.742353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.411881</td>\n",
       "      <td>1.408791</td>\n",
       "      <td>13.119227</td>\n",
       "      <td>9.936669</td>\n",
       "      <td>0.627281</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.053022</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.079515</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 fundus_image_left  \\\n",
       "participant_id cohort research_stage array_index                     \n",
       "0              10k    00_00_visit    0               /path/to/file   \n",
       "1              10k    00_00_visit    0               /path/to/file   \n",
       "2              10k    00_00_visit    0               /path/to/file   \n",
       "\n",
       "                                                 fundus_image_right  \\\n",
       "participant_id cohort research_stage array_index                      \n",
       "0              10k    00_00_visit    0                /path/to/file   \n",
       "1              10k    00_00_visit    0                /path/to/file   \n",
       "2              10k    00_00_visit    0                /path/to/file   \n",
       "\n",
       "                                                 collection_date  \\\n",
       "participant_id cohort research_stage array_index                   \n",
       "0              10k    00_00_visit    0                2022-11-16   \n",
       "1              10k    00_00_visit    0                2022-06-30   \n",
       "2              10k    00_00_visit    0                2021-10-05   \n",
       "\n",
       "                                                  artery_average_width_left  \\\n",
       "participant_id cohort research_stage array_index                              \n",
       "0              10k    00_00_visit    0                         18430.284751   \n",
       "1              10k    00_00_visit    0                         17315.398780   \n",
       "2              10k    00_00_visit    0                         15375.866993   \n",
       "\n",
       "                                                  artery_average_width_right  \\\n",
       "participant_id cohort research_stage array_index                               \n",
       "0              10k    00_00_visit    0                          19038.547771   \n",
       "1              10k    00_00_visit    0                          19099.489575   \n",
       "2              10k    00_00_visit    0                          19855.576862   \n",
       "\n",
       "                                                  artery_distance_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                    \n",
       "0              10k    00_00_visit    0                                   3.668175   \n",
       "1              10k    00_00_visit    0                                   2.095461   \n",
       "2              10k    00_00_visit    0                                   2.776472   \n",
       "\n",
       "                                                  artery_distance_tortuosity_right  \\\n",
       "participant_id cohort research_stage array_index                                     \n",
       "0              10k    00_00_visit    0                                    3.271147   \n",
       "1              10k    00_00_visit    0                                    1.634782   \n",
       "2              10k    00_00_visit    0                                    2.747015   \n",
       "\n",
       "                                                  artery_fractal_dimension_left  \\\n",
       "participant_id cohort research_stage array_index                                  \n",
       "0              10k    00_00_visit    0                                 1.355673   \n",
       "1              10k    00_00_visit    0                                 1.368933   \n",
       "2              10k    00_00_visit    0                                 1.360404   \n",
       "\n",
       "                                                  artery_fractal_dimension_right  \\\n",
       "participant_id cohort research_stage array_index                                   \n",
       "0              10k    00_00_visit    0                                  1.343602   \n",
       "1              10k    00_00_visit    0                                  1.363413   \n",
       "2              10k    00_00_visit    0                                  1.362699   \n",
       "\n",
       "                                                  artery_squared_curvature_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                             \n",
       "0              10k    00_00_visit    0                                           40.648267   \n",
       "1              10k    00_00_visit    0                                           24.253169   \n",
       "2              10k    00_00_visit    0                                            9.742353   \n",
       "\n",
       "                                                  ...  \\\n",
       "participant_id cohort research_stage array_index  ...   \n",
       "0              10k    00_00_visit    0            ...   \n",
       "1              10k    00_00_visit    0            ...   \n",
       "2              10k    00_00_visit    0            ...   \n",
       "\n",
       "                                                  vein_fractal_dimension_left  \\\n",
       "participant_id cohort research_stage array_index                                \n",
       "0              10k    00_00_visit    0                               1.410553   \n",
       "1              10k    00_00_visit    0                               1.387527   \n",
       "2              10k    00_00_visit    0                               1.411881   \n",
       "\n",
       "                                                  vein_fractal_dimension_right  \\\n",
       "participant_id cohort research_stage array_index                                 \n",
       "0              10k    00_00_visit    0                                1.403108   \n",
       "1              10k    00_00_visit    0                                1.332864   \n",
       "2              10k    00_00_visit    0                                1.408791   \n",
       "\n",
       "                                                  vein_squared_curvature_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                           \n",
       "0              10k    00_00_visit    0                                         14.208195   \n",
       "1              10k    00_00_visit    0                                          8.999069   \n",
       "2              10k    00_00_visit    0                                         13.119227   \n",
       "\n",
       "                                                  vein_squared_curvature_tortuosity_right  \\\n",
       "participant_id cohort research_stage array_index                                            \n",
       "0              10k    00_00_visit    0                                           6.098432   \n",
       "1              10k    00_00_visit    0                                           8.702682   \n",
       "2              10k    00_00_visit    0                                           9.936669   \n",
       "\n",
       "                                                  vein_tortuosity_density_left  \\\n",
       "participant_id cohort research_stage array_index                                 \n",
       "0              10k    00_00_visit    0                                0.700187   \n",
       "1              10k    00_00_visit    0                                0.740806   \n",
       "2              10k    00_00_visit    0                                0.627281   \n",
       "\n",
       "                                                  vein_tortuosity_density_right  \\\n",
       "participant_id cohort research_stage array_index                                  \n",
       "0              10k    00_00_visit    0                                 0.698546   \n",
       "1              10k    00_00_visit    0                                 0.708911   \n",
       "2              10k    00_00_visit    0                                 0.675100   \n",
       "\n",
       "                                                  vein_vessel_density_left  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                            0.046645   \n",
       "1              10k    00_00_visit    0                            0.037896   \n",
       "2              10k    00_00_visit    0                            0.053022   \n",
       "\n",
       "                                                 vein_vessel_density_right  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                            0.045864   \n",
       "1              10k    00_00_visit    0                            0.046853   \n",
       "2              10k    00_00_visit    0                            0.048063   \n",
       "\n",
       "                                                 vessel_density_left  \\\n",
       "participant_id cohort research_stage array_index                       \n",
       "0              10k    00_00_visit    0                      0.080377   \n",
       "1              10k    00_00_visit    0                      0.074197   \n",
       "2              10k    00_00_visit    0                      0.079515   \n",
       "\n",
       "                                                  vessel_density_right  \n",
       "participant_id cohort research_stage array_index                        \n",
       "0              10k    00_00_visit    0                        0.078671  \n",
       "1              10k    00_00_visit    0                        0.064578  \n",
       "2              10k    00_00_visit    0                        0.082102  \n",
       "\n",
       "[3 rows x 76 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dfs['fundus'].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All availbale fields (columns) in all tables can be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artery_squared_curvature_tortuosity_right',\n",
       " 'fundus_image_binary_vein_segmentation_right',\n",
       " 'timezone',\n",
       " 'fundus_image_quality_good_score_left',\n",
       " 'fundus_image_quality_prediction_left']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.fields[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access any of the fields (e.g., `vein_average_width_right`, `age`) or indices (e.g., `research_stage`) from any of the tables via the data loader API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>vein_average_width_right</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>research_stage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>18436.428634</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0</td>\n",
       "      <td>00_00_visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>18888.160314</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1</td>\n",
       "      <td>00_00_visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>19013.865043</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>00_00_visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>18809.012493</td>\n",
       "      <td>44.6</td>\n",
       "      <td>1</td>\n",
       "      <td>00_00_visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>19428.986690</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0</td>\n",
       "      <td>00_00_visit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vein_average_width_right  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                        18436.428634   \n",
       "1              10k    00_00_visit    0                        18888.160314   \n",
       "2              10k    00_00_visit    0                        19013.865043   \n",
       "3              10k    00_00_visit    0                        18809.012493   \n",
       "4              10k    00_00_visit    0                        19428.986690   \n",
       "\n",
       "                                                   age  sex research_stage  \n",
       "participant_id cohort research_stage array_index                            \n",
       "0              10k    00_00_visit    0            43.5    0    00_00_visit  \n",
       "1              10k    00_00_visit    0            53.7    1    00_00_visit  \n",
       "2              10k    00_00_visit    0            26.2    0    00_00_visit  \n",
       "3              10k    00_00_visit    0            44.6    1    00_00_visit  \n",
       "4              10k    00_00_visit    0            50.3    0    00_00_visit  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl[['research_stage', 'vein_average_width_right', 'age', 'sex']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample's bulk file from the main table (where it is stored in the field `fundus_image_left`), converts it to an absolute path, and loads the file. This is repeated for 3 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the `load_func` and the results are concatenated by deafult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "dl.dfs['fundus']['fundus_image_left'] = [f'M0/images/fundus_{i}.png' for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=25x25>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=25x25>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=25x25>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.load_sample_data('fundus_image_left', [0, 1, 2], load_func=Image.open, concat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
